% Experiments - Simplified Version
\section{Experiments}
\label{sec:experiments}

We evaluate SWIVL on bimanual manipulation of articulated objects in an SE(2) planar benchmark. Our experiments address the following key question:

\begin{itemize}[leftmargin=2em]
    \item[\textbf{Q1.}] Does SWIVL improve task success and reduce fighting forces compared to position control and classical impedance control baselines?
\end{itemize}

%------------------------------------------------------------------------------
\subsection{Experimental Setup}
\label{sec:exp_setup}
%------------------------------------------------------------------------------

\paragraph{SE(2) Benchmark Rationale.}
While our method (Section~\ref{sec:method}) is formulated for SE(3) with $k$-DoF articulated objects, we validate in SE(2) with 1-DoF objects. This deliberate simplification enables rigorous evaluation while preserving the essential challenges: \textbf{(i)} the fundamental phenomena---force coupling, constraint satisfaction, compliant coordination---manifest identically in planar and spatial settings; \textbf{(ii)} all architectural components (projection operators $P_{i,\parallel}, P_{i,\perp}$, metric tensor $G(\alpha)$, impedance modulation $d_\parallel, d_\perp$) remain fully exercised; and \textbf{(iii)} the mathematical structure (Lie group, screw theory, twist-wrench duality) reduces consistently from SE(3). Extension to SE(3) requires only scaling observation/action dimensions. See Appendix~\ref{app:se2} for complete SE(2) instantiation.

\paragraph{Environment.}
We use a 512$\times$512 pixel planar workspace with dual 3-DoF end-effectors under direct body wrench control $\mathcal{F}_i = [m_z, f_x, f_y]^\top$. Each end-effector provides 3-axis F/T sensing. The hierarchical architecture combines high-level planning (10 Hz) with low-level control (100 Hz).

\paragraph{Tasks and Objects.}
We evaluate on \textbf{2 articulated objects} spanning two joint types (Figure~\ref{fig:objects}):
\begin{itemize}[leftmargin=1.5em]
    \item \textbf{Revolute}: Angular articulation---rotation about a pivot point. One arm drives rotation while the other must comply.
    \item \textbf{Prismatic}: Linear articulation---sliding along an axis. One arm drives extension/retraction while the other accommodates.
\end{itemize}
Each object satisfies the SE(2) holonomic constraint ${}^s\mathcal{V}_l - {}^s\mathcal{V}_r = \mathcal{S}\dot{q}_{obj}$ with constant body-frame screw axes $\mathcal{B}_l, \mathcal{B}_r \in \mathbb{R}^3$. Tasks require manipulating objects from randomized initial configurations to goal configurations. \textbf{Success criteria}: position error $<$10 pixels, orientation error $<$5°, joint error $<$5° or 5 pixels, with maintained grasp. Each configuration is tested over \textbf{100 trials}.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/objects.jpg}
    \caption{\textbf{Benchmark objects.} Two SE(2) articulated objects spanning two joint types: revolute (angular articulation) and prismatic (linear articulation).}
    \label{fig:objects}
\end{figure}

\paragraph{High-Level Planner.}
All methods share a common high-level planner: a \textbf{Flow Matching Policy} trained via behavior cloning on expert demonstrations. The policy outputs action chunks---sequences of desired end-effector poses $\{T_{sd_i}[\tau]\}_{\tau=0}^{H}$---at 10 Hz. This architecture represents state-of-the-art imitation learning for manipulation, providing temporally consistent motion intentions without explicit reasoning about contact dynamics or inter-arm force coordination. By fixing the high-level planner across all methods, we isolate the contribution of the low-level control strategy.

\paragraph{Methods Under Comparison.}
We compare three low-level control strategies, all receiving identical action chunks from the Flow Matching Policy:

\begin{itemize}[leftmargin=1.5em]
    \item \textbf{Position Control (Pos-Ctrl)}: The action chunks are tracked via high-stiffness position control. This represents the standard deployment of imitation learning policies, where learned poses are directly executed without force awareness. The controller applies:
    \begin{equation}
        \mathcal{F}_{cmd,i} = K_p (p_{d_i} - p_i) + K_d (\dot{p}_{d_i} - \dot{p}_i)
    \end{equation}
    with high gains $K_p, K_d$ to minimize tracking error, prioritizing trajectory fidelity over compliance.
    
    \item \textbf{Impedance Control (Imp-Ctrl)}: The action chunks are tracked via classical SE(3) impedance control with linearized approximations. This baseline employs the standard mass-spring-damper formulation:
    \begin{equation}
        \mathcal{F}_{cmd,i} = D\xi_i + K\mathcal{E}_i + \mu_{b,i}
    \end{equation}
    where $\xi_i$ is the twist error, $\mathcal{E}_i$ is the pose error, and $D, K$ are fixed diagonal damping and stiffness matrices. This approach assumes small orientation errors ($J_l^{-1}(e_R) \approx I_3$) and uses isotropic impedance parameters without object-aware decomposition.
    
    \item \textbf{SWIVL (Ours)}: The action chunks are processed through the full SWIVL framework: (i) the Reference Twist Field Generator converts sparse waypoints into dense, stable reference twists with pose-error correction, (ii) the RL policy modulates impedance variables $(d_{i,\parallel}, d_{i,\perp}, k_{p_i}, \alpha)$ conditioned on screw axes and wrench feedback, and (iii) the Screw-Decomposed Impedance Controller executes compliant control with independent regulation of bulk and internal motions.
\end{itemize}

\paragraph{Implementation.}
For SWIVL, the policy observes reference twists $\mathcal{V}_i^{\text{ref}}$, screw axes $\mathcal{B}_i$, wrenches $\mathcal{F}_i$, and proprioception ($\mathbb{R}^{30}$ total), and outputs impedance variables $(d_{l,\parallel}, d_{r,\parallel}, d_{l,\perp}, d_{r,\perp}, k_{p_l}, k_{p_r}, \alpha) \in \mathbb{R}^7$. Training uses PPO with the reward from Eq.~\eqref{eq:reward}. For fair comparison, Imp-Ctrl uses the same control frequency (100 Hz) and receives identical trajectory inputs. Full architecture and hyperparameters are in Appendix~\ref{app:learning_settings}.

\paragraph{Metrics.}
\begin{itemize}[leftmargin=1.5em]
    \item \textbf{Success Rate} (\%): Task completion within error thresholds
    \item \textbf{Fighting Force} $F_{\text{fight}}$ (N): Time-averaged bulk wrench magnitude $\frac{1}{T}\sum_t \|\mathcal{F}_{i,\perp}(t)\|$
    \item \textbf{Constraint Violation} (px/s): Deviation from holonomic constraint $\|{}^s\mathcal{V}_l - {}^s\mathcal{V}_r - \mathcal{S}\dot{q}_{obj}\|$
    \item \textbf{Tracking RMSE} (px): End-effector trajectory error relative to reference
\end{itemize}

%------------------------------------------------------------------------------
\subsection{Results}
\label{sec:results}
%------------------------------------------------------------------------------

% ============================================================================
% TABLE: Main comparison results
% ============================================================================
\begin{table}[t]
\centering
\caption{\textbf{Quantitative comparison.} Performance across two joint types (100 trials each). All methods use the same Flow Matching Policy as high-level planner. Bold indicates best; $\pm$ shows standard error.}
\label{tab:main_results}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Method} & \textbf{Success (\%)$\uparrow$} & \textbf{$F_{\text{fight}}$ (N)$\downarrow$} & \textbf{CViol (px/s)$\downarrow$} & \textbf{RMSE (px)$\downarrow$} \\
\midrule
\multicolumn{5}{l}{\textit{Revolute Joint}} \\
Pos-Ctrl & [--] & [--] & [--] & [--] \\
Imp-Ctrl & [--] & [--] & [--] & [--] \\
SWIVL (Ours) & [--] & [--] & [--] & [--] \\
\midrule
\multicolumn{5}{l}{\textit{Prismatic Joint}} \\
Pos-Ctrl & [--] & [--] & [--] & [--] \\
Imp-Ctrl & [--] & [--] & [--] & [--] \\
SWIVL (Ours) & [--] & [--] & [--] & [--] \\
\midrule
\multicolumn{5}{l}{\textit{Average (All Objects)}} \\
Pos-Ctrl & [--] & [--] & [--] & [--] \\
Imp-Ctrl & [--] & [--] & [--] & [--] \\
SWIVL (Ours) & \textbf{[--]} & \textbf{[--]} & \textbf{[--]} & [--] \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:main_results} presents quantitative results across all joint types. We observe consistent patterns across the two object categories. Figure~\ref{fig:swivl_inference} illustrates a successful manipulation sequence using the full SWIVL framework, demonstrating coordinated bimanual control with learned impedance modulation.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/swivl_inference.jpg}
    \caption{\textbf{SWIVL inference sequence.} Time-ordered frames showing successful bimanual manipulation of an articulated object. The impedance parameters panel (left) displays learned values: damping coefficients $d_\parallel, d_\perp$ for internal and bulk motions, stiffness $k_p$, and characteristic length $\alpha$. Red arrows indicate wrench feedback from F/T sensors. The policy adaptively modulates compliance to achieve coordinated manipulation while maintaining low fighting forces.}
    \label{fig:swivl_inference}
\end{figure}

\paragraph{Success Rate.}
SWIVL achieves the highest success rates across both joint types, with an average improvement of [--]\% over Pos-Ctrl and [--]\% over Imp-Ctrl. The performance gap is pronounced for both articulated objects (revolute and prismatic), where kinematic constraints impose strict coordination requirements that constraint-unaware controllers cannot satisfy.

\paragraph{Fighting Force Reduction.}
The most striking difference appears in fighting force $F_{\text{fight}}$. Pos-Ctrl generates the highest internal forces across all conditions because high-stiffness tracking of kinematically inconsistent references directly translates to inter-arm stress. Imp-Ctrl reduces forces through passive compliance but cannot eliminate them systematically. SWIVL achieves [--]$\times$ reduction in fighting forces compared to Pos-Ctrl by explicitly decomposing wrenches into productive (along constraint) and non-productive (orthogonal) components, then learning to suppress the latter through impedance modulation.

\paragraph{Constraint Satisfaction.}
Constraint violation (CViol) measures deviation from the holonomic constraint ${}^s\mathcal{V}_l - {}^s\mathcal{V}_r = \mathcal{S}\dot{q}_{obj}$. Pos-Ctrl shows the highest violations as it prioritizes trajectory tracking over constraint satisfaction. Imp-Ctrl's isotropic compliance provides no geometric structure to guide motion along valid constraint manifolds. SWIVL's screw-decomposed control naturally respects constraints by projecting motions onto object-centric subspaces, achieving near-zero violations for articulated objects.

\paragraph{Tracking Accuracy.}
Interestingly, SWIVL maintains competitive tracking RMSE despite prioritizing compliance over rigid tracking. This suggests that fighting forces in baselines actually \textit{degrade} tracking by causing grasp perturbations and object drift. By suppressing harmful internal forces, SWIVL achieves smoother trajectories that better approximate the high-level planner's intentions.

% ============================================================================
% FIGURE PLACEHOLDER: Force profiles comparison
% ============================================================================
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{figures/force_comparison.pdf}
%     \caption{\textbf{Fighting force profiles.} Time evolution of bulk wrench magnitude $\|\mathcal{F}_{i,\perp}\|$ during revolute manipulation. Pos-Ctrl exhibits persistent high forces throughout; Imp-Ctrl reduces magnitude but cannot eliminate constraint-violating components; SWIVL maintains consistently low fighting forces through learned impedance modulation.}
%     \label{fig:force_comparison}
% \end{figure}
% ============================================================================

%------------------------------------------------------------------------------
\subsection{Analysis}
\label{sec:analysis}
%------------------------------------------------------------------------------

\paragraph{Why Position Control Fails.}
Position control's fundamental limitation is its inability to accommodate kinematic constraints. When the high-level Flow Matching Policy outputs action chunks, these represent motion \textit{intentions} learned from demonstrations---they do not guarantee kinematic consistency between the two arms. Under high-stiffness control, even small inconsistencies ($<$1\% position error) accumulate into substantial fighting forces because the controller treats the reference as a hard constraint to be achieved regardless of physical consequences. This is particularly problematic for articulated objects where the holonomic constraint ${}^s\mathcal{V}_l - {}^s\mathcal{V}_r = \mathcal{S}\dot{q}_{obj}$ must be satisfied continuously. Figure~\ref{fig:failure_modes} illustrates two representative failure modes: (a) grasp drift caused by excessive fighting forces that destabilize the grasp (Figure~\ref{fig:failure_grasp_drift}), and (b) wrench limit violations where uncontrolled forces exceed safe operating thresholds (Figure~\ref{fig:failure_wrench_limit}).

\paragraph{Why Classical Impedance Control Is Insufficient.}
Classical impedance control introduces compliance but suffers from two key limitations in our setting:
\begin{enumerate}[leftmargin=1.5em]
    \item \textbf{Linearization errors}: The approximation $J_l^{-1}(e_R) \approx I_3$ assumes small orientation errors, which is violated during articulated manipulation where constraint mismatches can cause large trajectory deviations.
    \item \textbf{Lack of object awareness}: Fixed isotropic impedance parameters cannot distinguish between motion along the object's kinematic constraint (which should be compliant) and motion orthogonal to it (which may require stiffness for stability). This one-size-fits-all approach is fundamentally mismatched to articulated object manipulation.
\end{enumerate}

\begin{figure}[t]
    \centering
    \begin{subfigure}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/failure_grasp_drift.jpg}
        \caption{Grasp drift failure}
        \label{fig:failure_grasp_drift}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/failure_wrench_limit.jpg}
        \caption{Wrench limit exceeded}
        \label{fig:failure_wrench_limit}
    \end{subfigure}
    \caption{\textbf{Failure modes in baseline controllers.} (a) \textit{Grasp drift}: High-stiffness position control generates excessive fighting forces that cause the object to slip from the gripper, resulting in large goal error (L=143.4px, R=152.0px). (b) \textit{Wrench limit exceeded}: Without object-aware compliance, kinematically inconsistent commands produce dangerous wrench magnitudes (visualized as red arrows) that exceed safe operating limits, risking hardware damage and grasp instability.}
    \label{fig:failure_modes}
\end{figure}

\paragraph{SWIVL's Advantages.}
SWIVL addresses these limitations through three mechanisms:
\begin{enumerate}[leftmargin=1.5em]
    \item \textbf{Twist-driven formulation}: By incorporating pose errors into reference twists rather than computing elastic wrenches explicitly, SWIVL bypasses the nonlinear pose-error Jacobian $J_E$ (Section~\ref{sec:reference_twist_field}).
    \item \textbf{Screw-decomposed control}: The projection operators $P_{i,\parallel}, P_{i,\perp}$ partition the twist space into object-centric subspaces, enabling independent compliance for internal versus bulk motions (Section~\ref{sec:decomposed_impedance}).
    \item \textbf{Learned impedance modulation}: The RL policy discovers task-appropriate impedance strategies conditioned on real-time wrench feedback and object geometry, adapting compliance dynamically rather than relying on fixed parameters (Section~\ref{sec:impedance_learning}).
\end{enumerate}

% ============================================================================
% FIGURE PLACEHOLDER: Impedance variable visualization
% ============================================================================
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{figures/impedance_analysis.pdf}
%     \caption{\textbf{Learned impedance behavior.} (a) Damping coefficients $d_\parallel, d_\perp$ during revolute manipulation---the policy learns high $d_\perp$ (stiff bulk motion) with low $d_\parallel$ (compliant articulation). (b) Characteristic length $\alpha$ varies across joint types, discovering task-appropriate metric structures. (c) Impedance adjustment correlates with wrench feedback, demonstrating reactive force regulation.}
%     \label{fig:impedance_analysis}
% \end{figure}
% ============================================================================

\paragraph{Computational Efficiency.}
Reference twist field generation achieves $O(1)$ complexity per timestep through closed-form computation. Policy inference (forward pass through the FiLM-conditioned network) completes in $<$5 ms on a single CPU core, meeting the 100 Hz control requirement with margin. The projection operators $P_{i,\parallel}, P_{i,\perp}$ require only matrix-vector multiplications with pre-computed screw axes, adding negligible overhead. Overall, SWIVL's computational cost is compatible with real-time deployment on standard robot controllers.

%------------------------------------------------------------------------------
\subsection{Summary}
\label{sec:exp_summary}
%------------------------------------------------------------------------------

Our experiments validate SWIVL's core hypothesis: \textbf{explicit encoding of geometric constraints and wrench feedback enables robust bimanual manipulation that position control and classical impedance control cannot achieve}. Key findings:
\begin{enumerate}[leftmargin=2em]
    \item \textbf{Position control fails} for articulated objects because high-stiffness tracking of kinematically inconsistent references generates excessive fighting forces, leading to grasp instability and task failure.
    \item \textbf{Classical impedance control is insufficient} due to linearization assumptions that break down under large deviations and isotropic parameters that cannot distinguish object-centric motion subspaces.
    \item \textbf{SWIVL succeeds} by combining twist-driven impedance formulation, screw-decomposed control, and learned impedance modulation---achieving higher success rates with significantly reduced fighting forces across all joint types.
\end{enumerate}

These SE(2) results instantiate the general SE(3) methodology, providing evidence that SWIVL's principles---object-aware motion decomposition, wrench-adaptive compliance, and hierarchical integration with cognitive planners---will transfer to full spatial manipulation.