environment:
  control_dt: 0.01
  joint_type: revolute
  max_episode_steps: 1000
  name: BiArt
  object:
    link_length: 40.0
    link_mass: 0.5
    link_width: 12.0
  obs_type: state
  policy_dt: 0.1
  render_mode: null
evaluation:
  deterministic: true
  fps: 30
  metrics:
  - success_rate
  - tracking_error
  - wrench_magnitude
  - episode_length
  - task_completion_time
  num_episodes: 50
  output_dir: ./evaluation_results
  render_mode: rgb_array
  save_metrics: true
  save_trajectories: true
  save_videos: true
  visualize: true
experiment:
  name: swivl_impedance_learning
  notes: 'Hierarchical learning experiment:

    - High-level policy: Vision-based imitation learning

    - Low-level policy: RL for impedance parameter learning

    - Configurable controller types and HL policies

    '
  seed: 42
  tags:
  - bimanual
  - impedance_control
  - hierarchical_rl
hl_policy:
  act:
    action_dim: 6
    chunk_size: 10
    context_length: 10
    hidden_dim: 256
    num_layers: 6
    output_frequency: 10.0
    state_dim: 18
  checkpoint: null
  device: auto
  diffusion:
    action_dim: 6
    context_length: 10
    hidden_dim: 256
    num_diffusion_steps: 50
    num_layers: 4
    output_frequency: 10.0
    state_dim: 18
  flow_matching:
    action_dim: 6
    context_length: 10
    hidden_dim: 256
    num_diffusion_steps: 10
    num_layers: 4
    output_frequency: 10.0
    state_dim: 18
  type: flow_matching
hl_training:
  batch_size: 64
  dataset:
    augment: true
    num_demonstrations: 1000
    path: ./data/demonstrations
    shuffle: true
    train_split: 0.8
  dropout: 0.1
  learning_rate: 0.0001
  logging:
    log_interval: 100
    save_freq: 10
    tensorboard_log: ./logs/hl_policy/
    verbose: 1
  lr_scheduler:
    min_lr: 1.0e-06
    type: cosine
    warmup_epochs: 10
  num_epochs: 100
  optimizer: adam
  output:
    checkpoint_dir: ./checkpoints
    checkpoint_name_template: '{policy_type}_epoch_{epoch}.pth'
    metric: val_loss
    save_best_only: true
  weight_decay: 1.0e-05
ll_controller:
  robot:
    inertia: 0.1
    mass: 1.0
  screw_decomposed:
    max_damping_parallel: 50.0
    max_damping_perpendicular: 100.0
    max_stiffness_parallel: 100.0
    max_stiffness_perpendicular: 500.0
    min_damping_parallel: 1.0
    min_damping_perpendicular: 5.0
    min_stiffness_parallel: 5.0
    min_stiffness_perpendicular: 20.0
  se2_impedance:
    max_damping_angular: 20.0
    max_damping_linear: 50.0
    max_stiffness_angular: 100.0
    max_stiffness_linear: 200.0
    min_damping_angular: 0.5
    min_damping_linear: 1.0
    min_stiffness_angular: 5.0
    min_stiffness_linear: 10.0
  type: se2_impedance
rl_training:
  algorithm: ppo
  evaluation:
    deterministic: true
    eval_freq: 10000
    n_eval_episodes: 5
  logging:
    log_interval: 100
    save_freq: 50000
    tensorboard_log: ./logs/impedance_rl/
    verbose: 1
  output:
    checkpoint_dir: ./checkpoints
    checkpoint_name: impedance_policy.zip
  policy_network:
    activation: relu
    features_dim: 256
  ppo:
    batch_size: 64
    clip_range: 0.2
    ent_coef: 0.0
    gae_lambda: 0.95
    gamma: 0.99
    learning_rate: 0.0003
    max_grad_norm: 0.5
    n_epochs: 10
    n_steps: 2048
    vf_coef: 0.5
  reward:
    smoothness_weight: 0.01
    tracking_weight: 1.0
    wrench_weight: 0.1
  total_timesteps: 1000000
